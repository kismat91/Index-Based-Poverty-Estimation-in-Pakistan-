{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import math\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from fiona import Env\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'02123201001313'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to convert latitude and longitude to Bing Maps Quadkey\n",
    "def lat_lon_to_quadkey(lat, lon, level):\n",
    "    tile_size = 256\n",
    "\n",
    "    # Clip latitude and longitude to max values\n",
    "    lat = max(min(lat, 85.0511287798), -85.0511287798)\n",
    "    lon = max(min(lon, 180), -180)\n",
    "\n",
    "    # Convert latitude and longitude to pixel coordinates in a level zoom of the Earth\n",
    "    x = (lon + 180) / 360\n",
    "    sin_lat = math.sin(lat * math.pi / 180)\n",
    "    y = 0.5 - math.log((1 + sin_lat) / (1 - sin_lat)) / (4 * math.pi)\n",
    "\n",
    "    # Convert Earth coordinates to pixel coordinates\n",
    "    map_size = tile_size << level\n",
    "    pixel_x = int(clip(x * map_size + 0.5, 0, map_size - 1))\n",
    "    pixel_y = int(clip(y * map_size + 0.5, 0, map_size - 1))\n",
    "\n",
    "    # Convert pixel coordinates to tile coordinates\n",
    "    tile_x = int(math.floor(pixel_x / tile_size))\n",
    "    tile_y = int(math.floor(pixel_y / tile_size))\n",
    "\n",
    "    # Convert tile coordinates to a quadkey\n",
    "    quadkey = \"\"\n",
    "    for i in range(level, 0, -1):\n",
    "        digit = 0\n",
    "        mask = 1 << (i - 1)\n",
    "        if (tile_x & mask) != 0:\n",
    "            digit += 1\n",
    "        if (tile_y & mask) != 0:\n",
    "            digit += 2\n",
    "        quadkey += str(digit)\n",
    "\n",
    "    return quadkey\n",
    "\n",
    "# Function to clip a number to the specified minimum and maximum values\n",
    "def clip(n, min_value, max_value):\n",
    "    return min(max(n, min_value), max_value)\n",
    "\n",
    "# Test the function with an example coordinate\n",
    "test_quadkey = lat_lon_to_quadkey(45.0, -122.0, 14)\n",
    "test_quadkey\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: There are 509153 quadkeys without matching population data.\n",
      "    latitude  longitude    rwi  error         quadkey   population\n",
      "0  33.897776  70.037842 -0.074  0.624  12310221130231  3119.037109\n",
      "1  31.118794  66.807861 -0.569  0.368  12303111302200  1192.453247\n",
      "2  32.648625  73.245850 -0.193  0.498  12310322022121  4926.342285\n",
      "3  35.182788  72.894287 -0.178  0.355  12310213112323  1739.792480\n",
      "4  25.948166  69.268799 -0.530  0.450  12312201232000  1315.402466\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the raster data\n",
    "with rasterio.open('/Users/kismatkhatri/Downloads/pak_pd_2020_1km.tif') as src:\n",
    "    pop_data = src.read(1)  # Read the first band\n",
    "    # Create a mask for valid data (assuming no data values are represented as such)\n",
    "    mask = pop_data > 0  # Replace with the appropriate condition for valid data\n",
    "    rows, cols = np.where(mask)\n",
    "    coords = [src.xy(row, col) for row, col in zip(rows, cols)]  # Convert indices to coordinates\n",
    "    \n",
    "    # Convert the coordinates to quadkeys\n",
    "    quadkeys = [lat_lon_to_quadkey(lat, lon, 14) for lon, lat in coords]\n",
    "    population = pop_data[mask]  # Extract population values for valid data points\n",
    "    \n",
    "    # Create a DataFrame from the quadkeys and population\n",
    "    pop_quadkey_df = pd.DataFrame({'quadkey': quadkeys, 'population': population})\n",
    "\n",
    "# Aggregate the population by quadkeys to get the sum of the population per level 14 tile\n",
    "pop_quadkey_agg_df = pop_quadkey_df.groupby('quadkey')['population'].sum().reset_index()\n",
    "\n",
    "# Load RWI data and add quadkeys\n",
    "rwi_df = pd.read_csv('/Users/kismatkhatri/Documents/Capstone project/RWI.csv')\n",
    "rwi_df['quadkey'] = rwi_df.apply(lambda row: lat_lon_to_quadkey(row['latitude'], row['longitude'], 14), axis=1)\n",
    "\n",
    "# Join the aggregated population data with the RWI data based on the quadkey\n",
    "rwi_pop_joined_df = pd.merge(rwi_df, pop_quadkey_agg_df, on='quadkey', how='left')\n",
    "\n",
    "# Check for any mismatched quadkeys\n",
    "unmatched_quadkeys = rwi_pop_joined_df[rwi_pop_joined_df['population'].isnull()]['quadkey'].unique()\n",
    "if len(unmatched_quadkeys) > 0:\n",
    "    print(f\"Warning: There are {len(unmatched_quadkeys)} quadkeys without matching population data.\")\n",
    "\n",
    "# Save the joined DataFrame to a new CSV file\n",
    "rwi_pop_joined_df.to_csv('/Users/kismatkhatri/Documents/Capstone project/joined_RWI_population.csv', index=False)\n",
    "\n",
    "# Check the first few rows to ensure the population has been joined correctly\n",
    "print(rwi_pop_joined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pslm_data = pd.read_stata('/Users/kismatkhatri/Documents/Capstone project/310_PSLM201920_Rescaledbyhhsize_160654obs.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_list1 = [\n",
    "    \"W_dkw_inspiped\",\n",
    "    \"W_dkw_inshandpump\",\n",
    "    \"W_dkw_insmotorpump\",\n",
    "    \"W_dkw_insclosedwell\",\n",
    "    \"W_dkw_insopenwell\",\n",
    "    \"W_dkw_insprotsprng\",\n",
    "    \"W_dkw_insunprsprng\",\n",
    "    \"W_dkw_outpiped\",\n",
    "    \"W_dkw_outhandpump\",\n",
    "    \"W_dkw_outmotorpump\",\n",
    "    \"W_dkw_outclosedwell\",\n",
    "    \"W_dkw_outopenwell\",\n",
    "    \"W_dkw_outprotsprng\",\n",
    "    \"W_dkw_outunprsprng\",\n",
    "    \"W_dkw_pond\",\n",
    "    \"W_dkw_bottwater\",\n",
    "    \"W_dkw_tanker\",\n",
    "    \"W_dkw_filtration\",\n",
    "    \"W_dkw_other\",\n",
    "    \"W_toilet_notoilet\",\n",
    "    \"W_toilet_flushpub\",\n",
    "    \"W_toilet_flushtank\",\n",
    "    \"W_toilet_flushpit\",\n",
    "    \"W_toilet_flushopen\",\n",
    "    \"W_toilet_raiselat\",\n",
    "    \"W_toilet_pitlat\",\n",
    "    \"W_toilet_other\",\n",
    "    \"W_toiletshared\",\n",
    "    \"W_toiletprivate\",\n",
    "    \"H_cooking_firewood\",\n",
    "    \"H_cooking_gas\",\n",
    "    \"H_cooking_lpg\",\n",
    "    \"H_cooking_dung\",\n",
    "    \"H_cooking_crop\",\n",
    "    \"H_cooking_other\",\n",
    "    \"H_floor_earth\",\n",
    "    \"H_floor_ceramic\",\n",
    "    \"H_floor_cement\",\n",
    "    \"H_floor_bricks\",\n",
    "    \"H_floor_other\",\n",
    "    \"H_roof_rccrbc\",\n",
    "    \"H_roof_wood\",\n",
    "    \"H_roof_sheet\",\n",
    "    \"H_roof_grader\",\n",
    "    \"H_roof_other\",\n",
    "    \"H_walls_burntbricks\",\n",
    "    \"H_walls_mudbricks\",\n",
    "    \"H_walls_wood\",\n",
    "    \"H_walls_stones\",\n",
    "    \"H_walls_other\",\n",
    "    \"D_iradio\",\n",
    "    \"D_itelevsion\",\n",
    "    \"D_ilcdled\",\n",
    "    \"D_irefrigerator\",\n",
    "    \"D_ifreezer\",\n",
    "    \"D_iwashing\",\n",
    "    \"D_idryer\",\n",
    "    \"D_iairconditioning\",\n",
    "    \"D_iaircooler\",\n",
    "    \"D_ifan\",\n",
    "    \"D_istove\",\n",
    "    \"D_icookingrange\",\n",
    "    \"D_imicrowave\",\n",
    "    \"D_isewingmachine\",\n",
    "    \"D_iknitting\",\n",
    "    \"D_iiron\",\n",
    "    \"D_iwaterfilter\",\n",
    "    \"D_idonkeypump\",\n",
    "    \"D_iturbine\",\n",
    "    \"D_ichair\",\n",
    "    \"D_itable\",\n",
    "    \"D_iups\",\n",
    "    \"D_igenerator\",\n",
    "    \"D_isolarpanel\",\n",
    "    \"D_iheater\",\n",
    "    \"D_igeaser\",\n",
    "    \"D_ibicycle\",\n",
    "    \"D_imotorcyclescotter\",\n",
    "    \"D_irichshaw\",\n",
    "    \"D_icar\",\n",
    "    \"D_ivantruckbus\",\n",
    "    \"D_iboat\",\n",
    "    \"D_itractortralloy\",\n",
    "    \"D_iclock\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/n2c3c7jj1t5dv6zbxjqxzbnc0000gn/T/ipykernel_1993/3052149695.py:20: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  weighted_data = scaled_data * sqrt_weights[:, None]  # Using None instead of np.newaxis to avoid the warning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA variance explained: 25.60%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming Pslm_data and variables_list1 are defined and imported correctly.\n",
    "\n",
    "# Step 1: Extract the selected columns and drop rows with missing values\n",
    "selected_variables = Pslm_data[variables_list1].dropna().reset_index(drop=True)\n",
    "\n",
    "# Step 2: Perform Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(selected_variables)\n",
    "\n",
    "# Step 3: Calculate the square root of weights and adjust the scaled data\n",
    "weights = Pslm_data.loc[selected_variables.index, 'popwt']\n",
    "sqrt_weights = np.sqrt(weights)\n",
    "\n",
    "# This ensures that the weights are applied to each observation\n",
    "weighted_data = scaled_data * sqrt_weights[:, None]  # Using None instead of np.newaxis to avoid the warning\n",
    "\n",
    "# Step 4: Apply PCA on the weighted data\n",
    "pca = PCA(n_components=1)\n",
    "pca.fit(weighted_data)\n",
    "\n",
    "# Multiply the PCA components by the square root of the eigenvalues if necessary\n",
    "components = pca.transform(weighted_data) * np.sqrt(pca.explained_variance_)\n",
    "\n",
    "# Step 5: Analyze the PCA output\n",
    "explained_variance = pca.explained_variance_ratio_[0]\n",
    "print(f'PCA variance explained: {explained_variance * 100:.2f}%')\n",
    "\n",
    "# Create the basis vector DataFrame\n",
    "basis_vector = pd.DataFrame(pca.components_.T, index=variables_list1, columns=['Magnitude'])\n",
    "\n",
    "# Sort the basis vector by magnitude in descending order\n",
    "basis_vector.sort_values(by='Magnitude', ascending=False, inplace=True)\n",
    "\n",
    "# Normalize the wealth index if necessary to match the expected range\n",
    "wealth_index = components.squeeze()\n",
    "min_max_scaler = MinMaxScaler(feature_range=(-2, 2))\n",
    "Pslm_data['Wealth_Index1'] = min_max_scaler.fit_transform(wealth_index.reshape(-1, 1))\n",
    "\n",
    "# Save the basis vector and updated DataFrame to CSV files\n",
    "basis_vector.to_csv('PSLM_DATA_with_basis_vector.csv')\n",
    "Pslm_data.to_csv('PSLM_data_with_wealth_index.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kismatkhatri/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3309: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load and aggregate PSLM data by district\n",
    "pslm_data = pd.read_csv(\"PSLM_data_with_wealth_index.csv\")\n",
    "pslm_district_wealth = pslm_data.groupby('District')['Wealth_Index1'].mean().reset_index()\n",
    "\n",
    "# Load the joined RWI data with population information\n",
    "rwi_data = pd.read_csv(\"/Users/kismatkhatri/Documents/Capstone project/joined_RWI_population.csv\")\n",
    "\n",
    "# Load districts shapefile with environment settings to restore .shx index files\n",
    "with Env(SHAPE_RESTORE_SHX='YES'):\n",
    "    districts = gpd.read_file('/Users/kismatkhatri/Documents/Capstone project/shapefile/pak_admbnda_adm2_wfp_20220909.shp')\n",
    "\n",
    "# Convert RWI data into GeoDataFrame\n",
    "geometry = [Point(xy) for xy in zip(rwi_data['longitude'], rwi_data['latitude'])]\n",
    "rwi_data = gpd.GeoDataFrame(rwi_data, geometry=geometry)\n",
    "\n",
    "# Ensure CRS match\n",
    "rwi_data.crs = districts.crs\n",
    "\n",
    "# Perform the spatial join to associate RWI data with districts\n",
    "rwi_data_with_district = gpd.sjoin(rwi_data, districts, how=\"left\", op=\"within\")\n",
    "\n",
    "# Filter RWI data by specified provinces\n",
    "provinces_to_include = [\"Punjab\", \"Sindh\", \"Balochistan\", \"Khyber Pakhtunkhwa\", \"Islamabad\"]\n",
    "filtered_rwi_district_data = rwi_data_with_district[rwi_data_with_district['ADM1_EN'].isin(provinces_to_include)]\n",
    "\n",
    "# Aggregate RWI data by district, now including the population\n",
    "rwi_district_agg = filtered_rwi_district_data.groupby('ADM2_EN').agg({'rwi': 'mean', 'population': 'sum'}).reset_index()\n",
    "\n",
    "\n",
    "# Define the population threshold based on the actual population data from RWI\n",
    "population_threshold = 0.14 * rwi_district_agg['population'].sum()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kismatkhatri/opt/anaconda3/lib/python3.9/site-packages/geopandas/geodataframe.py:1543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping dictionary for district names\n",
    "district_mapping = {\n",
    "    'Central Karachi': 'Karachi Central',\n",
    "    'Chitral Lower': 'Chitral',\n",
    "    'Chitral Upper': 'Chitral',\n",
    "    'D. I. Khan': 'Dera Ismail Khan',\n",
    "    'East Karachi': 'Karachi East',\n",
    "    'Kashmore': 'Kashmor',\n",
    "    'Kohistan Lower': 'Kohistan',\n",
    "    'Kohistan Upper': 'Kohistan',\n",
    "    'Korangi Karachi': 'Korangi',\n",
    "    'Leiah': 'Layyah',\n",
    "    'Malakand': 'Malakand Protected Area',\n",
    "    'Malir Karachi': 'Malir',\n",
    "    'Shaheed Benazir Abad': 'Shaheed Benazirabad',\n",
    "    'South Karachi': 'Karachi South',\n",
    "    'Tor Ghar': 'Torghar',\n",
    "    'West Karachi': 'Karachi West',\n",
    "    'Shaheed Sikandarabad': 'Surab'\n",
    "}\n",
    "\n",
    "# Apply the mapping dictionary to the 'ADM2_EN' column of the filtered_rwi_district_data dataframe\n",
    "filtered_rwi_district_data['ADM2_EN'] = filtered_rwi_district_data['ADM2_EN'].replace(district_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.59\n",
      "Recall: 0.61\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sort districts by wealth index from PSLM and RWI\n",
    "pslm_sorted = pslm_district_wealth.sort_values('Wealth_Index1').reset_index(drop=True)\n",
    "rwi_sorted = rwi_district_agg.sort_values('rwi').reset_index(drop=True)\n",
    "\n",
    "# Initialize targeted districts lists\n",
    "targeted_districts_pslm = []\n",
    "targeted_districts_rwi = []\n",
    "\n",
    "# Initialize population counters\n",
    "population_counter_pslm = 0\n",
    "population_counter_rwi = 0\n",
    "\n",
    "# Target districts until the population threshold is reached\n",
    "for index, row in rwi_sorted.iterrows():\n",
    "    if population_counter_rwi + row['population'] <= population_threshold:\n",
    "        targeted_districts_rwi.append(row['ADM2_EN'])\n",
    "        population_counter_rwi += row['population']\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Assuming RWI population data is used as a proxy for PSLM due to lack of population data in PSLM\n",
    "for index, row in pslm_sorted.iterrows():\n",
    "    corresponding_rwi_row = rwi_sorted[rwi_sorted['ADM2_EN'] == row['District']]\n",
    "    if corresponding_rwi_row.empty:\n",
    "        # No matching district found in RWI data, skip this district\n",
    "        continue\n",
    "    if population_counter_pslm + corresponding_rwi_row['population'].iloc[0] <= population_threshold:\n",
    "        targeted_districts_pslm.append(row['District'])\n",
    "        population_counter_pslm += corresponding_rwi_row['population'].iloc[0]\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Calculate performance metrics\n",
    "true_positives = set(targeted_districts_pslm).intersection(set(targeted_districts_rwi))\n",
    "precision = len(true_positives) / len(targeted_districts_rwi)\n",
    "recall = len(true_positives) / len(targeted_districts_pslm)\n",
    "\n",
    "# Output the performance\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
