{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iYTj2dTcuLSJ",
    "outputId": "d65a0e53-ea64-40ee-b554-2f9227df16da"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# import sys\n",
    "\n",
    "# # Mount Google Drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # Get the absolute path of the current folder\n",
    "# abspath_curr = '/content/drive/My Drive/Colab Notebooks/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ajDIx4KZuSRb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from statsmodels.multivariate.pca import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rPeL_LwgugDJ",
    "outputId": "698fbac5-356c-4a9c-cbc9-85e9340e8199"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   codep  codepd  codepdd  codepddr  codepddrp    codepddrph Province  \\\n",
      "0      1     105     1052     10520  105201001  1.052010e+10       KP   \n",
      "1      1     105     1052     10520  105201001  1.052010e+10       KP   \n",
      "2      1     105     1052     10520  105201001  1.052010e+10       KP   \n",
      "3      1     105     1052     10520  105201001  1.052010e+10       KP   \n",
      "4      1     105     1052     10520  105201001  1.052010e+10       KP   \n",
      "\n",
      "   Division District  rural  ...  F_ninterormore  F_nhighlorless  \\\n",
      "0  Malakand  Chitral  urban  ...               3               4   \n",
      "1  Malakand  Chitral  urban  ...               3               6   \n",
      "2  Malakand  Chitral  urban  ...               4               3   \n",
      "3  Malakand  Chitral  urban  ...               0               3   \n",
      "4  Malakand  Chitral  urban  ...               3               4   \n",
      "\n",
      "   F_nhighlormore  F_nnolaborinfo  F_nemployed  F_nseeking  \\\n",
      "0               2               0            3           5   \n",
      "1               0               0            4           3   \n",
      "2               3               0            2           0   \n",
      "3               0               0            2           1   \n",
      "4               2               0            1           0   \n",
      "\n",
      "   F_nseniornonpensioned  F_pensioned  F_2ormoreemployed  F_0employed  \n",
      "0                      0            3                  1            0  \n",
      "1                      0            2                  1            0  \n",
      "2                      0            0                  1            0  \n",
      "3                      0            1                  1            0  \n",
      "4                      1            0                  0            0  \n",
      "\n",
      "[5 rows x 393 columns]\n"
     ]
    }
   ],
   "source": [
    "Hies_data = pd.read_stata('310_HIES201819_Rescaledbyhhsize_24618obs.dta')\n",
    "print(Hies_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CIMlO9l-zVV5",
    "outputId": "5abea98d-40d8-42a4-8fd0-08fcd09fba77"
   },
   "outputs": [],
   "source": [
    "# !pip install pyreadstat\n",
    "# import pyreadstat\n",
    "\n",
    "# # Assuming you have a Stata dataset file named 'your_data.dta'\n",
    "# df, meta = pyreadstat.read_dta(abspath_curr + '/data/PSLM_HIES/310_HIES201819_Rescaledbyhhsize_24618obs.dta')\n",
    "\n",
    "# # Access variable labels from the metadata\n",
    "# variable_labels = meta.column_labels\n",
    "\n",
    "# # Print variable labels\n",
    "# for i, var_label in enumerate(variable_labels):\n",
    "#     var_name = df.columns[i]\n",
    "#     print(f\"Variable: {var_name}, Label: {var_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 249
    },
    "id": "pSv3Vl0tuntk",
    "outputId": "c9a0cb50-b250-47a3-f401-13e2f3a555a4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codep</th>\n",
       "      <th>codepd</th>\n",
       "      <th>codepdd</th>\n",
       "      <th>codepddr</th>\n",
       "      <th>codepddrp</th>\n",
       "      <th>codepddrph</th>\n",
       "      <th>Province</th>\n",
       "      <th>Division</th>\n",
       "      <th>District</th>\n",
       "      <th>rural</th>\n",
       "      <th>...</th>\n",
       "      <th>F_ninterormore</th>\n",
       "      <th>F_nhighlorless</th>\n",
       "      <th>F_nhighlormore</th>\n",
       "      <th>F_nnolaborinfo</th>\n",
       "      <th>F_nemployed</th>\n",
       "      <th>F_nseeking</th>\n",
       "      <th>F_nseniornonpensioned</th>\n",
       "      <th>F_pensioned</th>\n",
       "      <th>F_2ormoreemployed</th>\n",
       "      <th>F_0employed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>401</td>\n",
       "      <td>4013</td>\n",
       "      <td>40130</td>\n",
       "      <td>401302004</td>\n",
       "      <td>4.013020e+10</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Kalat</td>\n",
       "      <td>Awaran</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>401</td>\n",
       "      <td>4013</td>\n",
       "      <td>40130</td>\n",
       "      <td>401302004</td>\n",
       "      <td>4.013020e+10</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Kalat</td>\n",
       "      <td>Awaran</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>401</td>\n",
       "      <td>4013</td>\n",
       "      <td>40130</td>\n",
       "      <td>401302004</td>\n",
       "      <td>4.013020e+10</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Kalat</td>\n",
       "      <td>Awaran</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>401</td>\n",
       "      <td>4013</td>\n",
       "      <td>40130</td>\n",
       "      <td>401302004</td>\n",
       "      <td>4.013020e+10</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Kalat</td>\n",
       "      <td>Awaran</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>401</td>\n",
       "      <td>4013</td>\n",
       "      <td>40130</td>\n",
       "      <td>401302004</td>\n",
       "      <td>4.013020e+10</td>\n",
       "      <td>Balochistan</td>\n",
       "      <td>Kalat</td>\n",
       "      <td>Awaran</td>\n",
       "      <td>urban</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 393 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   codep  codepd  codepdd  codepddr  codepddrp    codepddrph     Province  \\\n",
       "0      4     401     4013     40130  401302004  4.013020e+10  Balochistan   \n",
       "1      4     401     4013     40130  401302004  4.013020e+10  Balochistan   \n",
       "2      4     401     4013     40130  401302004  4.013020e+10  Balochistan   \n",
       "3      4     401     4013     40130  401302004  4.013020e+10  Balochistan   \n",
       "4      4     401     4013     40130  401302004  4.013020e+10  Balochistan   \n",
       "\n",
       "  Division District  rural  ...  F_ninterormore  F_nhighlorless  \\\n",
       "0    Kalat   Awaran  urban  ...               3               6   \n",
       "1    Kalat   Awaran  urban  ...               0               2   \n",
       "2    Kalat   Awaran  urban  ...               0               4   \n",
       "3    Kalat   Awaran  urban  ...               3               3   \n",
       "4    Kalat   Awaran  urban  ...               0               2   \n",
       "\n",
       "   F_nhighlormore  F_nnolaborinfo  F_nemployed  F_nseeking  \\\n",
       "0               0               0            4           1   \n",
       "1               0               0            5           4   \n",
       "2               0               0            1           0   \n",
       "3               1               0            4           3   \n",
       "4               0               0            4           3   \n",
       "\n",
       "   F_nseniornonpensioned  F_pensioned  F_2ormoreemployed  F_0employed  \n",
       "0                      0            1                  1            0  \n",
       "1                      0            4                  1            0  \n",
       "2                      0            0                  0            0  \n",
       "3                      0            3                  1            0  \n",
       "4                      0            3                  1            0  \n",
       "\n",
       "[5 rows x 393 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pslm_data = pd.read_stata('310_PSLM201920_Rescaledbyhhsize_160654obs.dta')\n",
    "Pslm_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iud7fY-v0p2l",
    "outputId": "3abadc19-5723-4db8-905e-2f182f9d3f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1481.977539\n",
       "1         1481.977539\n",
       "2          846.844299\n",
       "3         1693.688599\n",
       "4         1481.977539\n",
       "             ...     \n",
       "160649    2399.060547\n",
       "160650    2095.615234\n",
       "160651    1191.542236\n",
       "160652    1787.313354\n",
       "160653    2801.316650\n",
       "Name: popwt, Length: 160654, dtype: float32"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pslm_data['popwt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDNShoFAzWWk",
    "outputId": "7ffb8cab-0dba-4a5f-ffbf-b51e00854545"
   },
   "outputs": [],
   "source": [
    "# # Assuming you have a Stata dataset file named 'your_data.dta'\n",
    "# df, meta = pyreadstat.read_dta(abspath_curr + '/data/PSLM_HIES/310_PSLM201920_Rescaledbyhhsize_160654obs.dta')\n",
    "\n",
    "# # Access variable labels from the metadata\n",
    "# variable_labels = meta.column_labels\n",
    "\n",
    "# # Print variable labels\n",
    "# for i, var_label in enumerate(variable_labels):\n",
    "#     var_name = df.columns[i]\n",
    "#     print(f\"Variable: {var_name}, Label: {var_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTYhu6xM6C9H"
   },
   "source": [
    "## Summary of PSLM and HIES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Lzc068fzqm2",
    "outputId": "867a1550-8a57-4f07-f173-c8f3030792d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Weighted Mean PSLM  Weighted Std PSLM  \\\n",
      "W_dkw_inspiped                 0.188993           0.391503   \n",
      "W_dkw_inshandpump              0.179021           0.383370   \n",
      "W_dkw_insmotorpump             0.277011           0.447522   \n",
      "W_dkw_insclosedwell            0.012176           0.109670   \n",
      "W_dkw_insopenwell              0.006802           0.082194   \n",
      "...                                 ...                ...   \n",
      "D_icar                         0.062710           0.242440   \n",
      "D_ivantruckbus                 0.009387           0.096431   \n",
      "D_iboat                        0.000640           0.025297   \n",
      "D_itractortralloy              0.027484           0.163488   \n",
      "D_iclock                       0.609786           0.487798   \n",
      "\n",
      "                     Missing Values PSLM  Weighted Mean HIES  \\\n",
      "W_dkw_inspiped                         0            0.172982   \n",
      "W_dkw_inshandpump                      0            0.181647   \n",
      "W_dkw_insmotorpump                     0            0.296236   \n",
      "W_dkw_insclosedwell                    0            0.012423   \n",
      "W_dkw_insopenwell                      0            0.004698   \n",
      "...                                  ...                 ...   \n",
      "D_icar                                 0            0.061234   \n",
      "D_ivantruckbus                         0            0.008663   \n",
      "D_iboat                                0            0.000331   \n",
      "D_itractortralloy                      0            0.025874   \n",
      "D_iclock                               0            0.520112   \n",
      "\n",
      "                     Weighted Std HIES  Missing Values HIES  \n",
      "W_dkw_inspiped                0.378232                    0  \n",
      "W_dkw_inshandpump             0.385553                    0  \n",
      "W_dkw_insmotorpump            0.456596                    0  \n",
      "W_dkw_insclosedwell           0.110762                    0  \n",
      "W_dkw_insopenwell             0.068381                    0  \n",
      "...                                ...                  ...  \n",
      "D_icar                        0.239758                    0  \n",
      "D_ivantruckbus                0.092674                    0  \n",
      "D_iboat                       0.018203                    0  \n",
      "D_itractortralloy             0.158760                    0  \n",
      "D_iclock                      0.499595                    0  \n",
      "\n",
      "[84 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "variables_list1 = [\n",
    "    \"W_dkw_inspiped\",\n",
    "    \"W_dkw_inshandpump\",\n",
    "    \"W_dkw_insmotorpump\",\n",
    "    \"W_dkw_insclosedwell\",\n",
    "    \"W_dkw_insopenwell\",\n",
    "    \"W_dkw_insprotsprng\",\n",
    "    \"W_dkw_insunprsprng\",\n",
    "    \"W_dkw_outpiped\",\n",
    "    \"W_dkw_outhandpump\",\n",
    "    \"W_dkw_outmotorpump\",\n",
    "    \"W_dkw_outclosedwell\",\n",
    "    \"W_dkw_outopenwell\",\n",
    "    \"W_dkw_outprotsprng\",\n",
    "    \"W_dkw_outunprsprng\",\n",
    "    \"W_dkw_pond\",\n",
    "    \"W_dkw_bottwater\",\n",
    "    \"W_dkw_tanker\",\n",
    "    \"W_dkw_filtration\",\n",
    "    \"W_dkw_other\",\n",
    "    \"W_toilet_notoilet\",\n",
    "    \"W_toilet_flushpub\",\n",
    "    \"W_toilet_flushtank\",\n",
    "    \"W_toilet_flushpit\",\n",
    "    \"W_toilet_flushopen\",\n",
    "    \"W_toilet_raiselat\",\n",
    "    \"W_toilet_pitlat\",\n",
    "    \"W_toilet_other\",\n",
    "    \"W_toiletshared\",\n",
    "    \"W_toiletprivate\",\n",
    "    \"H_cooking_firewood\",\n",
    "    \"H_cooking_gas\",\n",
    "    \"H_cooking_lpg\",\n",
    "    \"H_cooking_dung\",\n",
    "    \"H_cooking_crop\",\n",
    "    \"H_cooking_other\",\n",
    "    \"H_floor_earth\",\n",
    "    \"H_floor_ceramic\",\n",
    "    \"H_floor_cement\",\n",
    "    \"H_floor_bricks\",\n",
    "    \"H_floor_other\",\n",
    "    \"H_roof_rccrbc\",\n",
    "    \"H_roof_wood\",\n",
    "    \"H_roof_sheet\",\n",
    "    \"H_roof_grader\",\n",
    "    \"H_roof_other\",\n",
    "    \"H_walls_burntbricks\",\n",
    "    \"H_walls_mudbricks\",\n",
    "    \"H_walls_wood\",\n",
    "    \"H_walls_stones\",\n",
    "    \"H_walls_other\",\n",
    "    \"D_iradio\",\n",
    "    \"D_itelevsion\",\n",
    "    \"D_ilcdled\",\n",
    "    \"D_irefrigerator\",\n",
    "    \"D_ifreezer\",\n",
    "    \"D_iwashing\",\n",
    "    \"D_idryer\",\n",
    "    \"D_iairconditioning\",\n",
    "    \"D_iaircooler\",\n",
    "    \"D_ifan\",\n",
    "    \"D_istove\",\n",
    "    \"D_icookingrange\",\n",
    "    \"D_imicrowave\",\n",
    "    \"D_isewingmachine\",\n",
    "    \"D_iknitting\",\n",
    "    \"D_iiron\",\n",
    "    \"D_iwaterfilter\",\n",
    "    \"D_idonkeypump\",\n",
    "    \"D_iturbine\",\n",
    "    \"D_ichair\",\n",
    "    \"D_itable\",\n",
    "    \"D_iups\",\n",
    "    \"D_igenerator\",\n",
    "    \"D_isolarpanel\",\n",
    "    \"D_iheater\",\n",
    "    \"D_igeaser\",\n",
    "    \"D_ibicycle\",\n",
    "    \"D_imotorcyclescotter\",\n",
    "    \"D_irichshaw\",\n",
    "    \"D_icar\",\n",
    "    \"D_ivantruckbus\",\n",
    "    \"D_iboat\",\n",
    "    \"D_itractortralloy\",\n",
    "    \"D_iclock\"\n",
    "]\n",
    "\n",
    "# Assuming 'weights' is the column in your DataFrame that contains the survey weights\n",
    "weights_pslm = Pslm_data['popwt']\n",
    "weights_hies = Hies_data['popwt_f']\n",
    "\n",
    "selected_variables_pslm = Pslm_data[variables_list1]\n",
    "selected_variables_hies = Hies_data[variables_list1]\n",
    "\n",
    "# Calculate weighted means and standard deviations for PSLM data\n",
    "weighted_means_pslm = np.average(selected_variables_pslm, weights=weights_pslm, axis=0)\n",
    "weighted_std_pslm = np.sqrt(np.average((selected_variables_pslm - weighted_means_pslm)**2, weights=weights_pslm, axis=0))\n",
    "\n",
    "# Calculate weighted means and standard deviations for HIES data\n",
    "weighted_means_hies = np.average(selected_variables_hies, weights=weights_hies, axis=0)\n",
    "weighted_std_hies = np.sqrt(np.average((selected_variables_hies - weighted_means_hies)**2, weights=weights_hies, axis=0))\n",
    "\n",
    "# Count the number of missing values for each variable\n",
    "missing_values_pslm = selected_variables_pslm.isna().sum()\n",
    "missing_values_hies = selected_variables_hies.isna().sum()\n",
    "\n",
    "# Create a summary DataFrame\n",
    "Summary_data = pd.DataFrame({\n",
    "    'Weighted Mean PSLM': weighted_means_pslm,\n",
    "    'Weighted Std PSLM': weighted_std_pslm,\n",
    "    'Missing Values PSLM': missing_values_pslm,\n",
    "    'Weighted Mean HIES': weighted_means_hies,\n",
    "    'Weighted Std HIES': weighted_std_hies,\n",
    "    'Missing Values HIES': missing_values_hies\n",
    "}, index=variables_list1)\n",
    "\n",
    "print(Summary_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3azPgl7D6dfI"
   },
   "source": [
    "## PCA for PSLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Jp9ZBWz0YJq",
    "outputId": "5916712a-5918-446c-e4aa-bad8414fffc8"
   },
   "outputs": [],
   "source": [
    "# from statsmodels.multivariate.pca import PCA\n",
    "\n",
    "# selected_variables = Pslm_data[variables_list1].copy()\n",
    "\n",
    "\n",
    "# # Drop rows with missing values and reset the index to align with the weights\n",
    "# selected_variables.dropna(inplace=True)\n",
    "# selected_variables.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# # Perform Min-Max scaling\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(selected_variables)\n",
    "\n",
    "# # Ensure the weights are aligned with the scaled data\n",
    "# weights = Pslm_data.loc[selected_variables.index, 'popwt'].values\n",
    "# sqrt_weights = np.sqrt(weights)\n",
    "\n",
    "# # Adjust data using the square root of weights\n",
    "# # This step is crucial since weights in PCA are usually applied to rows, not columns\n",
    "# weighted_data = scaled_data * sqrt_weights[:, np.newaxis]\n",
    "\n",
    "# # Initialize the PCA object without specifying weights\n",
    "# # since we have already adjusted the data with weights\n",
    "# pca_model = PCA(weighted_data, ncomp=1, standardize=False, demean=False)\n",
    "\n",
    "# # Fit the PCA model\n",
    "# pca_model.fit()\n",
    "\n",
    "# # Extract the components and loadings\n",
    "# components = pca_model.factors\n",
    "# loadings = pca_model.loadings\n",
    "\n",
    "# # Analyze the PCA output\n",
    "# # Print the explained variance\n",
    "# explained_variance = pca_model.rsquare[0] if pca_model.rsquare.size > 0 else 0\n",
    "# print(f'PCA variance explained: {explained_variance * 100:.2f}%')\n",
    "\n",
    "# # Create the basis vector DataFrame\n",
    "# basis_vector = pd.DataFrame(loadings, index=variables_list1)\n",
    "\n",
    "# # Sort the basis vector by magnitude in descending order\n",
    "# basis_vector.sort_values(by=0, ascending=False, inplace=True)\n",
    "\n",
    "# # Save the basis vector to a CSV file\n",
    "# basis_vector.to_csv('basis_vector.csv')\n",
    "\n",
    "# # Add the wealth index as a new column in your DataFrame\n",
    "# Pslm_data['Wealth_Index'] = components.squeeze()\n",
    "\n",
    "# # Save the updated DataFrame with the wealth index to a new CSV file\n",
    "# Pslm_data.to_csv('data_with_wealth_index.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "ih2xITkhULr7",
    "outputId": "3cc1e8d7-3b92-495b-8767-9084c7a339a6"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "\n",
    "#files.download('PSLM_data_with_wealth_index.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az5wCuTB6q9j"
   },
   "source": [
    "##PCA for HIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LsncOHY11EwT",
    "outputId": "9696a657-34d4-45b1-f4a6-12eb91f78920"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/n2c3c7jj1t5dv6zbxjqxzbnc0000gn/T/ipykernel_23486/353823036.py:17: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  adjusted_data = scaled_data * sqrt_weights[:, np.newaxis]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA variance explained: 100.00%\n"
     ]
    }
   ],
   "source": [
    "weights = Hies_data['popwt']\n",
    "# Extract the selected columns\n",
    "selected_variables = Hies_data[variables_list1].copy()\n",
    "\n",
    "# Drop rows with missing values\n",
    "selected_variables = selected_variables.dropna()\n",
    "\n",
    "\n",
    "# Perform Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(selected_variables)\n",
    "\n",
    "# Calculate the square root of weights\n",
    "sqrt_weights = np.sqrt(weights)\n",
    "\n",
    "# Adjust the data using the square root of weights\n",
    "adjusted_data = scaled_data * sqrt_weights[:, np.newaxis]\n",
    "\n",
    "# Apply PCA\n",
    "pca_model = PCA(adjusted_data, ncomp=1, standardize=False, demean=False)\n",
    "asset_index = pca_model.factors.squeeze()\n",
    "\n",
    "# Print the explained variance\n",
    "eigenvalues = pca_model.eigenvals\n",
    "explained_variance_ratio = eigenvalues[0] / eigenvalues.sum()\n",
    "print('PCA variance explained: %.2f%%' % (100 * explained_variance_ratio))\n",
    "\n",
    "# Create the basis vector DataFrame\n",
    "basis_vector = pd.DataFrame({'Asset': variables_list1, 'Magnitude': pca_model.loadings[:, 0]})\n",
    "\n",
    "# Sort the basis vector by magnitude in descending order\n",
    "basis_vector = basis_vector.sort_values(by='Magnitude', ascending=False)\n",
    "\n",
    "# Save the basis vector to a CSV file\n",
    "basis_vector.to_csv('asset_index_HIES_basis_vector.csv', index=False)\n",
    "\n",
    "# Add the wealth index as a new column in your DataFrame\n",
    "Hies_data['Wealth_Index1'] = asset_index\n",
    "\n",
    "# Save the updated DataFrame with the wealth index to a new CSV file\n",
    "Hies_data.to_csv('HIES_data_with_wealth_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zg/n2c3c7jj1t5dv6zbxjqxzbnc0000gn/T/ipykernel_23486/3881456972.py:17: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  adjusted_data = scaled_data * sqrt_weights[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "weights = Pslm_data['popwt']\n",
    "# Extract the selected columns\n",
    "selected_variables = Pslm_data[variables_list1].copy()\n",
    "\n",
    "# Drop rows with missing values\n",
    "selected_variables = selected_variables.dropna()\n",
    "\n",
    "\n",
    "# Perform Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(selected_variables)\n",
    "\n",
    "# Calculate the square root of weights\n",
    "sqrt_weights = np.sqrt(weights)\n",
    "\n",
    "# Adjust the data using the square root of weights\n",
    "adjusted_data = scaled_data * sqrt_weights[:, np.newaxis]\n",
    "\n",
    "# Apply PCA\n",
    "pca_model = PCA(adjusted_data, ncomp=1, standardize=False, demean=False)\n",
    "asset_index = pca_model.factors.squeeze()\n",
    "\n",
    "# Print the explained variance\n",
    "eigenvalues = pca_model.eigenvals\n",
    "explained_variance_ratio = eigenvalues[0] / eigenvalues.sum()\n",
    "print('PCA variance explained: %.2f%%' % (100 * explained_variance_ratio))\n",
    "\n",
    "# Create the basis vector DataFrame\n",
    "basis_vector = pd.DataFrame({'Asset': variables_list1, 'Magnitude': pca_model.loadings[:, 0]})\n",
    "\n",
    "# Sort the basis vector by magnitude in descending order\n",
    "basis_vector = basis_vector.sort_values(by='Magnitude', ascending=False)\n",
    "\n",
    "# Save the basis vector to a CSV file\n",
    "basis_vector.to_csv('asset_index_HIES_basis_vector.csv', index=False)\n",
    "\n",
    "# Add the wealth index as a new column in your DataFrame\n",
    "Pslm_data['Wealth_Index1'] = asset_index\n",
    "\n",
    "# Save the updated DataFrame with the wealth index to a new CSV file\n",
    "Pslm_data.to_csv('HIES_data_with_wealth_index.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhtBi7ct8Yu3"
   },
   "source": [
    "## Distribution of a wealth index estimated in the HIES and PLSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DWULtwU0yizg",
    "outputId": "5d5c983c-7c6e-4420-cab9-7cdc48e98f51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                       mean        std    median  quantile\n",
       " Wealth_Index1  5.472701e-15  57.033203 -5.735145 -5.735145,\n",
       "             mean        std     median   quantile\n",
       " rural                                            \n",
       " rural -17.286529  48.756143 -24.874616 -24.874616\n",
       " urban  38.276474  55.361677  36.220478  36.220478,\n",
       "                   mean        std     median   quantile\n",
       " Province                                               \n",
       " Balochistan -42.282122  37.144642 -54.281374 -54.281374\n",
       " KP           -9.205018  50.865400 -18.325577 -18.325577\n",
       " Punjab       16.428473  56.180256  12.536481  12.536481\n",
       " Sindh       -10.805074  56.984513 -16.283876 -16.283876,\n",
       "                         mean        std     median   quantile\n",
       " Province    rural                                            \n",
       " Balochistan rural -50.335694  30.348568 -59.470153 -59.470153\n",
       "             urban  -6.747449  43.071952 -12.097627 -12.097627\n",
       " KP          rural -16.239301  45.181427 -23.944986 -23.944986\n",
       "             urban  41.771247  59.893647  36.323119  36.323119\n",
       " Punjab      rural   0.028604  48.115554  -2.890321  -2.890321\n",
       "             urban  52.525316  55.791376  50.996865  50.996865\n",
       " Sindh       rural -48.119536  37.712113 -58.080838 -58.080838\n",
       "             urban  25.513224  48.470149  25.153732  25.153732)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hies_data = pd.read_csv('PSLM_data_with_wealth_index.csv')\n",
    "pslm_data = pd.read_csv('HIES_data_with_wealth_index.csv')\n",
    "\n",
    "\n",
    "# Function to calculate distribution statistics of the wealth index\n",
    "def calculate_distribution_statistics(data, wealth_index_column='Wealth_Index1', group_by_columns=None):\n",
    "    if group_by_columns:\n",
    "        grouped_data = data.groupby(group_by_columns)\n",
    "        statistics = grouped_data[wealth_index_column].agg(['mean', 'std', 'median', 'quantile'])\n",
    "    else:\n",
    "        statistics = data[wealth_index_column].agg(['mean', 'std', 'median', 'quantile']).to_frame().transpose()\n",
    "    return statistics\n",
    "\n",
    "# Calculate distribution statistics for HIES dataset\n",
    "hies_national_stats = calculate_distribution_statistics(hies_data)\n",
    "hies_urban_rural_stats = calculate_distribution_statistics(hies_data, group_by_columns='rural')\n",
    "hies_province_stats = calculate_distribution_statistics(hies_data, group_by_columns='Province')\n",
    "hies_urban_rural_province_stats = calculate_distribution_statistics(hies_data, group_by_columns=['Province', 'rural'])\n",
    "\n",
    "# Calculate distribution statistics for PSLM dataset\n",
    "pslm_national_stats = calculate_distribution_statistics(pslm_data)\n",
    "pslm_urban_rural_stats = calculate_distribution_statistics(pslm_data, group_by_columns='rural')\n",
    "pslm_province_stats = calculate_distribution_statistics(pslm_data, group_by_columns='Province')\n",
    "pslm_urban_rural_province_stats = calculate_distribution_statistics(pslm_data, group_by_columns=['Province', 'rural'])\n",
    "\n",
    "# Display the results for HIES dataset\n",
    "hies_national_stats, hies_urban_rural_stats, hies_province_stats, hies_urban_rural_province_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F8DzMgwNGbHo"
   },
   "source": [
    "## Harmonizing wealth indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "XBjDl9lFGZfw",
    "outputId": "c3f81090-1aa9-406f-bee9-548cc0690244"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Wealth_Index1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Wealth_Index1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m mean_HIES \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(Hies_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWealth_Index1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m std_HIES \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(Hies_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWealth_Index1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m mean_PSLM \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(\u001b[43mPslm_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWealth_Index1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      6\u001b[0m std_PSLM \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mstd(Pslm_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWealth_Index1\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Visual inspection (histograms)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 3623\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3624\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3625\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3626\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3627\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Wealth_Index1'"
     ]
    }
   ],
   "source": [
    "# Calculate descriptive statistics\n",
    "mean_HIES = np.mean(Hies_data['Wealth_Index1'])\n",
    "std_HIES = np.std(Hies_data['Wealth_Index1'])\n",
    "\n",
    "mean_PSLM = np.mean(Pslm_data['Wealth_Index1'])\n",
    "std_PSLM = np.std(Pslm_data['Wealth_Index1'])\n",
    "\n",
    "# Visual inspection (histograms)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(Hies_data['Wealth_Index1'], bins=30, alpha=0.5, label='HIES')\n",
    "plt.hist(Pslm_data['Wealth_Index1'], bins=30, alpha=0.5, label='PSLM')\n",
    "plt.legend(loc='upper right')\n",
    "plt.xlabel('Wealth Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Assuming HIES_data and PSLM_data are pandas DataFrames\n",
    "# Align the data to have the same length\n",
    "min_length = min(len(Hies_data), len(Pslm_data))\n",
    "HIES_data = Hies_data.iloc[:min_length]\n",
    "PSLM_data = Pslm_data.iloc[:min_length]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnHBJv_YsRlA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the PSLM and HIES data with wealth indices\n",
    "pslm_data = pd.read_csv('PSLM_data_with_wealth_index.csv')\n",
    "hies_data = pd.read_csv('HIES_data_with_wealth_index.csv')\n",
    "\n",
    "# Add survey weights\n",
    "pslm_data['weights'] = pslm_data['popwt']\n",
    "hies_data['weights'] = hies_data['popwt_f']\n",
    "\n",
    "# Calculate weighted means and standard deviations for wealth indices\n",
    "weighted_mean_pslm = (pslm_data['Wealth_Index1'] * pslm_data['weights']).sum() / pslm_data['weights'].sum()\n",
    "weighted_std_pslm = ((pslm_data['Wealth_Index1'] - weighted_mean_pslm)**2 * pslm_data['weights']).sum() / pslm_data['weights'].sum()\n",
    "\n",
    "weighted_mean_hies = (hies_data['Wealth_Index1'] * hies_data['weights']).sum() / hies_data['weights'].sum()\n",
    "weighted_std_hies = ((hies_data['Wealth_Index1'] - weighted_mean_hies)**2 * hies_data['weights']).sum() / hies_data['weights'].sum()\n",
    "\n",
    "# Standardize wealth indices within each dataset\n",
    "pslm_data['Wealth_Index_PSLM_Standardized'] = (pslm_data['Wealth_Index1'] - weighted_mean_pslm) / weighted_std_pslm\n",
    "hies_data['Wealth_Index_HIES_Standardized'] = (hies_data['Wealth_Index1'] - weighted_mean_hies) / weighted_std_hies\n",
    "\n",
    "# Calculate weighted average for harmonized wealth index\n",
    "total_weights = pslm_data['weights'].sum() + hies_data['weights'].sum()\n",
    "harmonized_wealth_index_pslm = (pslm_data['Wealth_Index_PSLM_Standardized'] * pslm_data['weights']) / total_weights\n",
    "harmonized_wealth_index_hies = (hies_data['Wealth_Index_HIES_Standardized'] * hies_data['weights']) / total_weights\n",
    "\n",
    "# Add the harmonized wealth index to both datasets\n",
    "pslm_data['Harmonized_Wealth_Index1'] = harmonized_wealth_index_pslm\n",
    "hies_data['Harmonized_Wealth_Index1'] = harmonized_wealth_index_hies\n",
    "\n",
    "# Save the updated datasets with harmonized wealth indices\n",
    "pslm_data.to_csv('PSLM_data_with_harmonized_wealth_index.csv', index=False)\n",
    "hies_data.to_csv('HIES_data_with_harmonized_wealth_index.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vK3-V0Li5JU2",
    "outputId": "e08b92c9-5a83-484a-b4cc-059aa7f96bb0"
   },
   "outputs": [],
   "source": [
    "hies_data['Harmonized_Wealth_Index1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2atSEY12NJa"
   },
   "source": [
    "## Household wealth correlates with household expenditure in HIES Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4esugTYFx8_q",
    "outputId": "b9b5131e-ee00-4fea-8df3-4fb0acb2ea91"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "# Load the HIES data with the wealth index\n",
    "hies_data = pd.read_csv('HIES_data_with_wealth_index.csv')\n",
    "\n",
    "# Aggregate the data at the province level\n",
    "province_agg = hies_data.groupby('Province').agg({'Wealth_Index1': 'mean', 'lnexpM': 'mean'}).reset_index()\n",
    "\n",
    "# Calculate the Spearman rank correlation\n",
    "correlation, p_value = spearmanr(province_agg['Wealth_Index1'], province_agg['lnexpM'])\n",
    "\n",
    "# Print the results\n",
    "print(f\"Spearman Rank Correlation at Province Level: {correlation:.2f}\")\n",
    "print(f\"P-Value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-C1ajplezjzm"
   },
   "source": [
    "## Comparing the RWI with the wealth index from the PSLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e0eM0O4WziyH"
   },
   "outputs": [],
   "source": [
    "# Load the RWI data from the CSV file\n",
    "rwi_data = pd.read_csv(abspath_curr + '/data/pak_rwi.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uERXA3m40k-u",
    "outputId": "8ce07d6c-b2f0-4b5f-d65e-98d686fa25e0"
   },
   "outputs": [],
   "source": [
    "districts = gpd.read_file(abspath_curr + '/data/pak_admbnda_adm2_wfp_20220909.shp')\n",
    "print(districts.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6AytTqIt39HP",
    "outputId": "43b738aa-2e88-454d-93df-8857f7f85919"
   },
   "outputs": [],
   "source": [
    "geometry = [Point(xy) for xy in zip(rwi_data['longitude'], rwi_data['latitude'])]\n",
    "rwi_data = gpd.GeoDataFrame(rwi_data, geometry=geometry)\n",
    "\n",
    "# Perform the spatial join to associate RWI data with districts\n",
    "rwi_data_with_district = gpd.sjoin(rwi_data, districts, how=\"left\", op=\"within\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "cJMw__G-miku",
    "outputId": "d45926f3-325c-4c84-91ad-ec41ff1dc053"
   },
   "outputs": [],
   "source": [
    "# Filter the data to retain only the districts in Punjab, Sindh, Balochistan, KP, and Islamabad\n",
    "provinces_to_include = [\"Punjab\", \"Sindh\", \"Balochistan\", \"Khyber Pakhtunkhwa\", \"Islamabad\"]\n",
    "filtered_rwi_district_data = rwi_data_with_district[rwi_data_with_district['ADM1_EN'].isin(provinces_to_include)]\n",
    "\n",
    "filtered_rwi_district_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0M3j38wrqKs6",
    "outputId": "41bc2ce0-cadc-447f-eb7a-b2ef86bc090e"
   },
   "outputs": [],
   "source": [
    "# Create a mapping dictionary for district names\n",
    "district_mapping = {\n",
    "    'Central Karachi': 'Karachi Central',\n",
    "    'Chitral Lower': 'Chitral',\n",
    "    'Chitral Upper': 'Chitral',\n",
    "    'D. I. Khan': 'Dera Ismail Khan',\n",
    "    'East Karachi': 'Karachi East',\n",
    "    'Kashmore': 'Kashmor',\n",
    "    'Kohistan Lower': 'Kohistan',\n",
    "    'Kohistan Upper': 'Kohistan',\n",
    "    'Korangi Karachi': 'Korangi',\n",
    "    'Leiah': 'Layyah',\n",
    "    'Malakand': 'Malakand Protected Area',\n",
    "    'Malir Karachi': 'Malir',\n",
    "    'Shaheed Benazir Abad': 'Shaheed Benazirabad',\n",
    "    'South Karachi': 'Karachi South',\n",
    "    'Tor Ghar': 'Torghar',\n",
    "    'West Karachi': 'Karachi West',\n",
    "    'Shaheed Sikandarabad': 'Surab'\n",
    "}\n",
    "\n",
    "# Apply the mapping dictionary to the 'ADM2_EN' column of the filtered_rwi_district_data dataframe\n",
    "filtered_rwi_district_data['ADM2_EN'] = filtered_rwi_district_data['ADM2_EN'].replace(district_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9m226c1I35S9",
    "outputId": "9335625c-512a-407a-8cbe-066d3643cb7c"
   },
   "outputs": [],
   "source": [
    "district_mean_rwi = filtered_rwi_district_data.groupby('ADM2_EN')['rwi'].mean().reset_index()\n",
    "\n",
    "# Sort the districts by RWI score in descending order\n",
    "ranked_districts = district_mean_rwi.sort_values(by='rwi', ascending=False)\n",
    "\n",
    "# Print the ranked districts\n",
    "print(ranked_districts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykK3NofWxjxy",
    "outputId": "705e2f68-7a69-4d1b-8c14-75a2b0a57a3b"
   },
   "outputs": [],
   "source": [
    "\n",
    "pslm_data = pd.read_csv('PSLM_data_with_wealth_index.csv')\n",
    "# Aggregating Wealth Index for PSLM\n",
    "pslm_district_wealth = pslm_data.groupby('District')['Wealth_Index1'].mean().reset_index()\n",
    "\n",
    "# Filter the RWI data to include only the common districts\n",
    "common_districts = set(pslm_district_wealth['District'])\n",
    "filtered_rwi_data = filtered_rwi_district_data[filtered_rwi_district_data['ADM2_EN'].isin(common_districts)]\n",
    "\n",
    "# Aggregating RWI scores by district\n",
    "rwi_district_wealth = filtered_rwi_data.groupby('ADM2_EN')['rwi'].mean()\n",
    "\n",
    "# Ranking Districts based on wealth indices\n",
    "pslm_district_ranking = pslm_district_wealth.sort_values(by='Wealth_Index1', ascending=False).reset_index(drop=True)\n",
    "rwi_district_ranking = rwi_district_wealth.sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Save the rankings (optional)\n",
    "pslm_district_ranking.to_csv('pslm_district_ranking.csv', index=False)\n",
    "rwi_district_ranking.to_csv('rwi_district_ranking.csv', index=False)\n",
    "\n",
    "# Calculate Spearman's rank correlation between PSLM and RWI rankings\n",
    "corr_pslm_rwi, _ = spearmanr(pslm_district_ranking['Wealth_Index1'], rwi_district_ranking['rwi'])\n",
    "\n",
    "print(f\"Spearman's rank correlation between PSLM and RWI: {corr_pslm_rwi:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "syP18DrTySPw",
    "outputId": "aa98909f-4a6d-43bb-dd33-68d28f5a3574"
   },
   "outputs": [],
   "source": [
    "# 1. Scatter Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pslm_district_ranking['Wealth_Index1'], y=rwi_district_ranking['rwi'])\n",
    "plt.title(\"Scatter Plot of PSLM vs. RWI Wealth Indices\")\n",
    "plt.xlabel(\"PSLM Wealth Index\")\n",
    "plt.ylabel(\"RWI Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "lx5Gz95nySD0",
    "outputId": "6241686e-fc87-454b-8571-3904b378ae84"
   },
   "outputs": [],
   "source": [
    "# 2. Heatmap (Difference between rankings)\n",
    "# Assuming you have a shapefile 'districts_shapefile.shp' with district boundaries\n",
    "gdf = gpd.read_file(abspath_curr + '/data/pak_admbnda_adm2_wfp_20220909.shp')\n",
    "\n",
    "# Calculate the difference in rankings\n",
    "pslm_district_ranking['PSLM Rank'] = pslm_district_ranking.index + 1\n",
    "rwi_district_ranking['RWI Rank'] = rwi_district_ranking.index + 1\n",
    "merged_rankings = pd.merge(pslm_district_ranking, rwi_district_ranking, left_on='District', right_on='ADM2_EN')\n",
    "merged_rankings['Rank Difference'] = merged_rankings['PSLM Rank'] - merged_rankings['RWI Rank']\n",
    "\n",
    "# Merge with the geodataframe\n",
    "gdf = gdf.merge(merged_rankings, left_on='ADM2_EN', right_on='District', how='inner')\n",
    "\n",
    "# Plotting the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "gdf.plot(column='Rank Difference', cmap='coolwarm', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)\n",
    "plt.title(\"Difference in District Wealth Rankings between PSLM and RWI\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ClOsoDTd7rWK",
    "outputId": "f412dbc4-e380-44ab-ebd0-c02466623820"
   },
   "outputs": [],
   "source": [
    "# Merge the two datasets on the district names\n",
    "combined_data = pslm_district_ranking.merge(rwi_district_ranking, left_on='District', right_on='ADM2_EN')\n",
    "\n",
    "n_bootstrap_samples = 1000\n",
    "correlation_samples = []\n",
    "\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    # Randomly sample districts with replacement\n",
    "    sample = combined_data.sample(n=combined_data.shape[0], replace=True)\n",
    "\n",
    "    # Calculate the correlation for this resampled data\n",
    "    corr, _ = spearmanr(sample['Wealth_Index1'], sample['rwi'])\n",
    "    correlation_samples.append(corr)\n",
    "\n",
    "# Analyze bootstrap results\n",
    "bootstrap_mean = np.mean(correlation_samples)\n",
    "bootstrap_std = np.std(correlation_samples)\n",
    "confidence_interval = np.percentile(correlation_samples, [2.5, 97.5])\n",
    "\n",
    "print(f\"Bootstrap Mean Correlation: {bootstrap_mean:.2f}\")\n",
    "print(f\"Bootstrap Standard Deviation: {bootstrap_std:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({confidence_interval[0]:.2f}, {confidence_interval[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "_SvlY0Op9SnO",
    "outputId": "f41b9965-f5eb-4516-e885-db1182d37f04"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot of RWI vs PSLM scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=combined_data['Wealth_Index1'], y=combined_data['rwi'])\n",
    "plt.title(\"Scatter Plot of PSLM vs. RWI Wealth Indices\")\n",
    "plt.xlabel(\"PSLM Wealth Index\")\n",
    "plt.ylabel(\"RWI Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(abspath_curr + '/data/scatter_plot.png')\n",
    "plt.show()\n",
    "\n",
    "# Histograms\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# PSLM histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(combined_data['Wealth_Index1'], kde=True)\n",
    "plt.title('Distribution of PSLM Wealth Index')\n",
    "plt.xlabel('PSLM Wealth Index')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# RWI histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(combined_data['rwi'], kde=True)\n",
    "plt.title('Distribution of RWI Scores')\n",
    "plt.xlabel('RWI Score')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "plt.savefig(abspath_curr + '/data/histplot.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XAnAVYaD14jV"
   },
   "source": [
    "## Comparing the RWI with the  Harmonized Wealth index from the PSLM data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bIfeWZzMyR7z",
    "outputId": "3689ebf5-d84a-4ee4-a51a-b4b08210b1ab"
   },
   "outputs": [],
   "source": [
    "pslm_data1 = pd.read_csv('PSLM_data_with_harmonized_wealth_index.csv')\n",
    "# Aggregating Wealth Index for PSLM\n",
    "pslm_district_wealth1 = pslm_data1.groupby('District')['Harmonized_Wealth_Index1'].mean().reset_index()\n",
    "\n",
    "# Filter the RWI data to include only the common districts\n",
    "common_districts1 = set(pslm_district_wealth1['District'])\n",
    "filtered_rwi_data1 = filtered_rwi_district_data[filtered_rwi_district_data['ADM2_EN'].isin(common_districts)]\n",
    "\n",
    "# Aggregating RWI scores by district\n",
    "rwi_district_wealth1 = filtered_rwi_data1.groupby('ADM2_EN')['rwi'].mean()\n",
    "\n",
    "# Ranking Districts based on wealth indices\n",
    "pslm_district_ranking1 = pslm_district_wealth1.sort_values(by='Harmonized_Wealth_Index1', ascending=False).reset_index(drop=True)\n",
    "rwi_district_ranking1 = rwi_district_wealth1.sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Save the rankings (optional)\n",
    "pslm_district_ranking1.to_csv('pslm_district_ranking_with_HarmonizedWealthIndex.csv', index=False)\n",
    "rwi_district_ranking1.to_csv('rwi_district_ranking_with_rwi.csv', index=False)\n",
    "\n",
    "# Calculate Spearman's rank correlation between PSLM and RWI rankings\n",
    "corr_pslm_rwi, _ = spearmanr(pslm_district_ranking1['Harmonized_Wealth_Index1'], rwi_district_ranking1['rwi'])\n",
    "\n",
    "print(f\"Spearman's rank correlation between PSLM and RWI: {corr_pslm_rwi:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "yqPQiFdiycDF",
    "outputId": "4b03dce6-8213-4db1-ee99-7d4563b0ff31"
   },
   "outputs": [],
   "source": [
    "# 1. Scatter Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pslm_district_ranking1['Harmonized_Wealth_Index1'], y=rwi_district_ranking1['rwi'])\n",
    "plt.title(\"Scatter Plot of PSLM vs. RWI Wealth Indices\")\n",
    "plt.xlabel(\"PSLM harmonized Wealth Index\")\n",
    "plt.ylabel(\"RWI Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "APIXTWLLyb8X",
    "outputId": "54159ba2-d3d2-4fc9-89c1-5a847fdf88d4"
   },
   "outputs": [],
   "source": [
    "# 2. Heatmap (Difference between rankings)\n",
    "# Assuming you have a shapefile 'districts_shapefile.shp' with district boundaries\n",
    "gdf = gpd.read_file(abspath_curr + '/data/pak_admbnda_adm2_wfp_20220909.shp')\n",
    "\n",
    "# Calculate the difference in rankings\n",
    "pslm_district_ranking1['PSLM Rank'] = pslm_district_ranking1.index + 1\n",
    "rwi_district_ranking1['RWI Rank'] = rwi_district_ranking1.index + 1\n",
    "merged_rankings1 = pd.merge(pslm_district_ranking1, rwi_district_ranking1, left_on='District', right_on='ADM2_EN')\n",
    "merged_rankings1['Rank Difference'] = merged_rankings1['PSLM Rank'] - merged_rankings1['RWI Rank']\n",
    "\n",
    "# Merge with the geodataframe\n",
    "gdf = gdf.merge(merged_rankings1, left_on='ADM2_EN', right_on='District', how='inner')\n",
    "\n",
    "# Plotting the heatmap\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "gdf.plot(column='Rank Difference', cmap='coolwarm', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)\n",
    "plt.title(\"Difference in District Wealth Rankings between PSLM and RWI\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TBeT7UMUHk4C",
    "outputId": "9e6d823b-6723-4eee-d48e-24f874f2d7c3"
   },
   "outputs": [],
   "source": [
    "# Aggregate the error\n",
    "agg_error = filtered_rwi_district_data.groupby('ADM2_EN')['error'].mean().reset_index().sort_values(by='error', ascending=False)\n",
    "\n",
    "# Sorted Dot Plot\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.stripplot(data=agg_error, y='ADM2_EN', x='error', size=5, palette='viridis', jitter=False, linewidth=0.5)\n",
    "plt.title('Sorted Dot Plot of RWI Aggregated Error by District')\n",
    "plt.xlabel('Average Error')\n",
    "plt.ylabel('District')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(agg_error['error'], kde=True, bins=30, color='skyblue')\n",
    "plt.title('Histogram of RWI Aggregated Errors')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Number of Districts')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nuub0xVfyb4a",
    "outputId": "86479e2a-0a0c-4663-e4d5-63740eff126b"
   },
   "outputs": [],
   "source": [
    "# Merge the two datasets on the district names\n",
    "combined_data1 = pslm_district_ranking1.merge(rwi_district_ranking1, left_on='District', right_on='ADM2_EN')\n",
    "\n",
    "n_bootstrap_samples = 1000\n",
    "correlation_samples1 = []\n",
    "\n",
    "for _ in range(n_bootstrap_samples):\n",
    "    # Randomly sample districts with replacement\n",
    "    sample1 = combined_data1.sample(n=combined_data1.shape[0], replace=True)\n",
    "\n",
    "    # Calculate the correlation for this resampled data\n",
    "    corr1, _ = spearmanr(sample1['Harmonized_Wealth_Index1'], sample1['rwi'])\n",
    "    correlation_samples1.append(corr1)\n",
    "\n",
    "# Analyze bootstrap results\n",
    "bootstrap_mean1 = np.mean(correlation_samples1)\n",
    "bootstrap_std1 = np.std(correlation_samples1)\n",
    "confidence_interval1 = np.percentile(correlation_samples1, [2.5, 97.5])\n",
    "\n",
    "print(f\"Bootstrap Mean Correlation: {bootstrap_mean1:.2f}\")\n",
    "print(f\"Bootstrap Standard Deviation: {bootstrap_std1:.2f}\")\n",
    "print(f\"95% Confidence Interval: ({confidence_interval1[0]:.2f}, {confidence_interval1[1]:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ywtK_esjyb1W",
    "outputId": "43c65b5d-4474-4f8f-9e8a-5942b7978fb4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot of RWI vs PSLM scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=combined_data1['Harmonized_Wealth_Index1'], y=combined_data1['rwi'])\n",
    "plt.title(\"Scatter Plot of PSLM vs. RWI Wealth Indices\")\n",
    "plt.xlabel(\"PSLM Harmonize Wealth Index\")\n",
    "plt.ylabel(\"RWI Score\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Histograms\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# PSLM histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(combined_data1['Harmonized_Wealth_Index1'], kde=True)\n",
    "plt.title('Distribution of PSLM Harmonize Wealth Index')\n",
    "plt.xlabel('PSLM Harmonize Wealth Index')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# RWI histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.histplot(combined_data['rwi'], kde=True)\n",
    "plt.title('Distribution of RWI Scores')\n",
    "plt.xlabel('RWI Score')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtRKYQFa6FMA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "toLImmSX6FQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c74XzAXN6FUC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4fiyzmj6FXv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sh0FBvCn6FbD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4eOLXep6FeP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zy_eT00r6Fho"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxho-CWC6Fni"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k71FkA7H6Frf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ff52i_qJ6Fu8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "txr2bLbB6Fyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-dS9yB0WAwzp"
   },
   "source": [
    "## TASK 4: Leverage the higher resolution of the RWI: To what extent can be used for targeting of social programs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "id": "D7XFx_Q6ybyC",
    "outputId": "a578d911-3ecc-4a3b-90bf-cbc1b863ac46"
   },
   "outputs": [],
   "source": [
    "# 1. Wealth Distribution Within a Sample District (e.g., 'Karachi Central')\n",
    "sample_district_data = filtered_rwi_district_data[filtered_rwi_district_data['ADM2_EN'] == 'Karachi Central']\n",
    "sns.kdeplot(sample_district_data['rwi'], shade=True)\n",
    "plt.title('Wealth Distribution Within Karachi Central')\n",
    "plt.xlabel('RWI Score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-uEPZkJaybqJ",
    "outputId": "cc270f72-c906-4bee-b2f3-6f7c44d7a42d"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "num_districts_rwi = filtered_rwi_district_data['ADM2_EN'].nunique()\n",
    "\n",
    "# Set subplot dimensions for RWI\n",
    "num_cols_rwi = 8\n",
    "num_rows_rwi = math.ceil(num_districts_rwi / num_cols_rwi)\n",
    "\n",
    "plt.figure(figsize=(15, num_rows_rwi * 2))\n",
    "\n",
    "for idx, district in enumerate(filtered_rwi_district_data['ADM2_EN'].unique()):\n",
    "    plt.subplot(num_rows_rwi, num_cols_rwi, idx+1)\n",
    "    district_data = filtered_rwi_district_data[filtered_rwi_district_data['ADM2_EN'] == district]\n",
    "    sns.kdeplot(district_data['rwi'], fill=True)\n",
    "    plt.title(district)\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(abspath_curr + '/data/plot.png')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v0fJICMC94PZ"
   },
   "outputs": [],
   "source": [
    "rw_percentiles = filtered_rwi_district_data.groupby('ADM2_EN')['rwi'].quantile(0.10).reset_index()\n",
    "rw_percentiles.rename(columns={'rwi': 'RWI_10th_Percentile'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dwK3JBKC94CD"
   },
   "outputs": [],
   "source": [
    "pslm_percentiles = pslm_district_wealth.groupby('District')['Wealth_Index1'].quantile(0.10).reset_index()\n",
    "pslm_percentiles.rename(columns={'Wealth_Index1': 'PSLM_10th_Percentile'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7aPSfy1_-c1",
    "outputId": "a7dd97cf-b609-45f3-99fc-be0bf5d0eb32"
   },
   "outputs": [],
   "source": [
    "merged_percentiles = rw_percentiles.merge(pslm_percentiles, left_on='ADM2_EN', right_on='District', how='inner')\n",
    "print(merged_percentiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 798
    },
    "id": "mbJ09ZQaI6eW",
    "outputId": "1ea1a689-0f5d-475c-e015-2361f418a9e1"
   },
   "outputs": [],
   "source": [
    "merged_percentiles.set_index('ADM2_EN').plot(kind='bar', figsize=(20,10))\n",
    "plt.title('Comparison of 10th Percentile between RWI and PSLM data')\n",
    "plt.ylabel('Wealth Index Value')\n",
    "plt.xlabel('District')\n",
    "plt.tight_layout()\n",
    "\n",
    "#plt.savefig(abspath_curr + '/data/bar.png')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 563
    },
    "id": "8B6hJNjTI6b8",
    "outputId": "277e6fe4-adfc-4a47-bcb4-3eaba46e7abc"
   },
   "outputs": [],
   "source": [
    "# Extracting urban and rural data subsets from the PSLM data\n",
    "urban_data_pslm = pslm_data[pslm_data['rural'] == 'urban']\n",
    "rural_data_pslm = pslm_data[pslm_data['rural'] == 'rural']\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(urban_data_pslm['Wealth_Index1'], fill=True, label='Urban')\n",
    "sns.kdeplot(rural_data_pslm['Wealth_Index1'], fill=True, label='Rural')\n",
    "plt.legend()\n",
    "plt.title('Wealth Distribution in Urban vs. Rural Areas (PSLM Data)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hiI4zUV2I6ZI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQS_mehWI6WF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wYvsWsMI6Tj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPdxLcPuI6Qe"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sZfAR8mMI6Nk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1UCst207I6Kf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J8o7BXCqI6HH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VsgyH2mI6Ca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE7RuYY_I547"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y-xrseV4yRrp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
